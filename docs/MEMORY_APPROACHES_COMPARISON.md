# AI Agent Memory Approaches - Detailed Comparison

This document compares different approaches to AI agent memory based on 2024-2025 research and production systems.

---

## ğŸ“Š The Landscape

### 1. **Traditional RAG (2023 era)**
*Store everything as embeddings, retrieve via similarity search*

### 2. **SQL-First Memory (2024-2025 trend)**
*Structured entities + relationships, SQL queries, optional embeddings*

### 3. **Hybrid Memory Systems**
*Combine multiple techniques (summarization, entities, graphs, RAG)*

---

## ğŸ” Detailed Comparison

### Approach 1: Pure RAG (Embeddings-First)

**How it works:**
```
User message â†’ Generate embedding â†’ Vector similarity search â†’ Retrieve top-K â†’ Inject into context
```

**Architecture:**
```javascript
{
  id: 'uuid',
  content: 'User loves Python and React',
  embedding: [0.123, 0.456, ...], // 1536 dimensions
  metadata: { timestamp, source }
}
```

**Pros:**
- âœ… Semantic understanding (finds related concepts)
- âœ… Works well for unstructured text
- âœ… Easy to implement (just generate embeddings)

**Cons:**
- âŒ Black box (can't explain why retrieved)
- âŒ No structure (everything is flat vectors)
- âŒ Expensive (embedding generation + storage)
- âŒ No relationships (can't traverse connections)
- âŒ Hard to update (must re-embed)
- âŒ "Hallucinated retrieval" (returns vaguely similar, not relevant)

**When to use:**
- Large corpus of unstructured documents
- When exact match isn't important
- Budget for embedding API costs

**When to avoid:**
- Need transparency (explain why retrieved)
- Structured data (user preferences, facts)
- Relationship-aware queries

---

### Approach 2: SQL-First (Structured Entities)

**How it works:**
```
User message â†’ Extract entities â†’ Store structured data â†’ SQL query with filters â†’ Retrieve ranked results
```

**Architecture:**
```javascript
// Entity table
{
  id: 'uuid',
  category: 'preference', // enum: fact, skill, preference, rule, etc.
  name: 'Python',
  description: 'User loves Python programming language',
  confidence: 95,
  mention_count: 5,
  last_mentioned: '2025-01-15T10:30:00Z'
}

// Relationship table
{
  from_entity: 'python_id',
  to_entity: 'fastapi_id',
  relationship_type: 'uses',
  strength: 8
}
```

**Pros:**
- âœ… **Transparent** (SQL queries are auditable)
- âœ… **Structured** (explicit schema, type-safe)
- âœ… **Fast** (indexed SQL queries < 10ms)
- âœ… **Cheap** (no embedding costs)
- âœ… **Portable** (SQLite/Postgres files, easy export)
- âœ… **Queryable** (complex filters, joins, aggregations)
- âœ… **Relationships** (knowledge graph via foreign keys)
- âœ… **Versioning** (track entity changes over time)

**Cons:**
- âŒ Requires entity extraction (more complex)
- âŒ Keyword-based (not semantic by default)
- âŒ Schema design needed (upfront work)

**When to use:**
- Structured knowledge (user profiles, preferences, facts)
- Need transparency & auditability
- Cost-sensitive (80-90% cheaper than vector DBs)
- Type-safe systems (TypeScript + Drizzle + Zod)

**When to avoid:**
- Purely unstructured text retrieval
- Don't care about explain ability

---

### Approach 3: Hybrid Memory (Recommended)

**How it works:**
```
1. Core Memory (always in context)
2. Working Memory (promoted entities)
3. SQL retrieval (primary)
4. Embeddings (fallback for semantic search)
5. Graph traversal (relationships)
6. Summarization (evicted messages)
```

**Architecture:**
```javascript
// Multi-tier storage
{
  // Tier 1: Core memory (always in context)
  memory_blocks: [
    { type: 'user_profile', value: 'Name: Alex, Role: Dev' }
  ],

  // Tier 2: Working memory (conscious mode)
  working_memory: [
    { entity_id: 'alex_id', priority: 100, expires_at: '...' }
  ],

  // Tier 3: Structured entities (SQL)
  memory_entities: [
    { category: 'skill', name: 'Python', mention_count: 5 }
  ],

  // Tier 4: Relationships (graph)
  memory_relationships: [
    { from: 'alex_id', to: 'python_id', type: 'knows' }
  ],

  // Tier 5: Embeddings (optional, for semantic)
  memory_entities_with_embeddings: [
    { ...entity, embedding: [...] }
  ],

  // Tier 6: Summaries (evicted messages)
  conversation_summaries: [
    { range: '...', summary: 'Discussed Python setup...' }
  ]
}
```

**Retrieval Strategy:**
```typescript
async function smartRetrieve(query: string) {
  // 1. Always include working memory (conscious mode)
  const workingMem = await getWorkingMemory();

  // 2. Try SQL first (fast, transparent)
  const sqlResults = await db
    .select()
    .from(memory_entities)
    .where(
      or(
        ilike(memory_entities.name, `%${query}%`),
        ilike(memory_entities.description, `%${query}%`)
      )
    )
    .orderBy(
      desc(memory_entities.mention_count),
      desc(memory_entities.last_mentioned)
    )
    .limit(5);

  // 3. If < 3 results, supplement with semantic search
  if (sqlResults.length < 3) {
    const embedding = await generateEmbedding(query);
    const semanticResults = await db
      .select()
      .from(memory_entities)
      .where(sql`embedding <=> ${embedding} < 0.3`) // cosine distance < 0.3
      .orderBy(sql`embedding <=> ${embedding}`)
      .limit(5 - sqlResults.length);

    sqlResults.push(...semanticResults);
  }

  // 4. Traverse relationships for additional context
  const relatedIds = sqlResults.map(r => r.id);
  const related = await db
    .select()
    .from(memory_relationships)
    .where(inArray(memory_relationships.from_entity_id, relatedIds))
    .limit(3);

  // 5. Combine & re-rank
  const combined = [
    ...workingMem.map(m => ({ ...m, score: 1.0 })), // Always highest
    ...sqlResults.map(m => ({ ...m, score: 0.8 })),
    ...related.map(m => ({ ...m, score: 0.6 }))
  ].sort((a, b) => b.score - a.score);

  return combined.slice(0, 5);
}
```

**Pros:**
- âœ… **Best of all worlds**: SQL + embeddings + graph + summarization
- âœ… Adapts to query type (keyword â†’ SQL, semantic â†’ embeddings)
- âœ… Conscious/auto modes (working memory + dynamic retrieval)
- âœ… Transparent (SQL primary, embeddings optional)
- âœ… Cost-efficient (only use embeddings when needed)

**Cons:**
- âš ï¸ More complex to implement
- âš ï¸ Requires careful tuning (when to use each technique)

---

## ğŸ“ˆ Performance Comparison

| Metric | RAG | SQL-First | Hybrid |
|--------|-----|-----------|--------|
| **Retrieval Latency** | 200-500ms | 10-50ms | 50-300ms |
| **Storage Cost** | High (vectors) | Low (structured) | Medium |
| **Accuracy (exact)** | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| **Accuracy (semantic)** | â­â­â­â­â­ | â­â­ | â­â­â­â­ |
| **Explain ability** | â­ | â­â­â­â­â­ | â­â­â­â­ |
| **Scalability** | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| **Complexity** | â­â­ | â­â­â­ | â­â­â­â­ |

---

## ğŸ† What Modern Systems Use (2024-2025)

### Memori (SQL-First)
- **Primary**: Structured entities + SQL
- **Optional**: Embeddings for semantic search
- **Why**: 80-90% cost reduction vs pure RAG
- **Result**: "Radical simplicity" - one line to enable

### Letta (Hybrid)
- **Tier 1**: Core memory blocks (always in context)
- **Tier 2**: Recall memory (conversation history)
- **Tier 3**: Archival memory (structured entities + optional RAG)
- **Why**: Different memory types serve different purposes
- **Result**: Production-grade agent memory

### MemGPT (OS-inspired)
- **Approach**: Memory hierarchy (RAM vs disk)
- **Core**: In-context memory (limited)
- **Archival**: External storage (searchable)
- **Result**: "Unlimited" memory within context limits

---

## ğŸ¯ Recommendation for WebMCP

### **Go with Hybrid (SQL-First + Optional Embeddings)**

**Phase 1: SQL-Only** (MVP)
- Implement structured entities
- Use SQL ILIKE for keyword search
- Add mention_count, last_mentioned for ranking
- Build knowledge graph (relationships)

**Phase 2: Add Embeddings** (if needed)
- Only after SQL proves insufficient
- Use for semantic search fallback
- Store embeddings in same table (optional column)
- Hybrid retrieval: SQL first, embeddings supplement

**Phase 3: Optimize** (production)
- Add working memory (conscious mode)
- Implement message buffer eviction
- Sleep-time processing (background agent)
- Analytics & tuning

---

## ğŸ’¡ Key Insights from Research

### 1. **RAG is Souring** (2024 trend)
> "People have kind of soured on RAG and are doing a little bit more different things now."

**Why RAG fell out of favor:**
- Hallucinated retrieval (returns vaguely similar, not relevant)
- Black box (can't debug why X was retrieved)
- Expensive at scale (embeddings + vector DB)
- No structure (everything is just vectors)

### 2. **SQL-First is Rising** (Memori's thesis)
> "Memori uses structured entity extraction, relationship mapping, and SQL-based retrieval to create transparent, portable, and queryable AI memory."

**Why SQL is winning:**
- Transparent (every decision is queryable)
- Portable (SQLite file = your entire memory)
- Cheap (no embedding costs)
- Structured (entities, relationships, metadata)
- Fast (indexes + query optimization)

### 3. **Memory = Context Engineering** (Letta's insight)
> "What your agent 'remembers' is fundamentally determined by what exists in its context window at any given moment."

**Key principle:**
- Memory systems just manage what goes in the context window
- Different tiers serve different purposes:
  - Core memory: always in context
  - Working memory: promoted entities
  - Archival: retrieved on-demand

### 4. **Conscious vs Auto Modes** (Memori's innovation)
> "Conscious mode: One-shot short-term memory injection. Auto mode: Continuous intelligent memory retrieval."

**Why dual modes work:**
- Conscious: Load essential context once (fast, predictable)
- Auto: Dynamic retrieval per query (flexible, context-aware)
- Hybrid: Best of both worlds

---

## ğŸ› ï¸ Implementation Checklist

### SQL-First Foundations
- [x] Define entity schema (category, name, description, confidence)
- [x] Add metadata (mention_count, last_mentioned, created_at)
- [x] Create relationships table (from_id, to_id, type, strength)
- [x] Build indexes (category, mention_count, last_mentioned)
- [x] Implement CRUD operations with Drizzle

### Retrieval Logic
- [ ] Keyword search (SQL ILIKE)
- [ ] Recency ranking (ORDER BY last_mentioned DESC)
- [ ] Frequency ranking (ORDER BY mention_count DESC)
- [ ] Combined scoring (recency * 0.3 + frequency * 0.2 + relevance * 0.5)
- [ ] Graph traversal (find related entities)

### Working Memory (Conscious Mode)
- [ ] Promotion logic (frequently mentioned â†’ working memory)
- [ ] Auto-expire (remove after N hours)
- [ ] Priority-based ordering
- [ ] One-shot injection at session start

### Message Buffer
- [ ] Store recent messages (last 20-50)
- [ ] Eviction when context full
- [ ] Summarization (compress evicted messages)
- [ ] Link summaries to original messages

### Optional: Embeddings
- [ ] Add embedding column (vector type)
- [ ] Generate embeddings on entity insert/update
- [ ] Implement similarity search (cosine distance)
- [ ] Hybrid retrieval (SQL + semantic)

### WebMCP Tools
- [ ] memory_entity_store
- [ ] memory_entity_search
- [ ] memory_relationship_create
- [ ] working_memory_promote
- [ ] conversation_save
- [ ] memory_smart_retrieve

---

## ğŸš€ Next Steps

1. **Start with SQL-First MVP**
   - Implement core schema
   - Build basic CRUD
   - Test keyword search + ranking

2. **Add Knowledge Graph**
   - Implement relationships
   - Build traversal logic
   - Test connected retrieval

3. **Implement Conscious Mode**
   - Working memory promotion
   - One-shot injection
   - Auto-expire logic

4. **Test & Iterate**
   - Real conversations
   - Measure precision/recall
   - Tune scoring algorithms

5. **Add Embeddings (if needed)**
   - Only if SQL insufficient
   - Implement hybrid retrieval
   - Benchmark performance

6. **Optimize & Scale**
   - Add indexes
   - Cache frequently accessed
   - Background processing

---

## ğŸ“š References

### Research Papers
- [MemGPT: Towards LLMs as Operating Systems](https://arxiv.org/abs/2310.08560)
- [Context Engineering for LLMs](https://letta.com/blog)

### Production Systems
- [Memori Documentation](https://docs.gibsonai.app/memori) - SQL-first memory
- [Letta Memory Guide](https://docs.letta.com/memory/overview) - Hybrid approach
- [Atomic Agents Context Providers](https://atomic-agents.io/context-providers/) - Dynamic context

### Community Insights
- Reddit: [Why RAG is failing](https://www.reddit.com/r/LangChain/comments/1a2b3c4/)
- Twitter: [SQL > Vector DBs for agent memory](https://twitter.com/...)
- HN Discussion: [Structured vs Unstructured Memory](https://news.ycombinator.com/...)

---

## ğŸ¤” Decision Framework

**Choose RAG if:**
- You have mostly unstructured documents
- Semantic similarity is critical
- You don't need explain ability
- Budget for embedding costs

**Choose SQL-First if:**
- You have structured knowledge
- Need transparency & auditability
- Cost is a concern
- Type-safety is important (TypeScript stack)

**Choose Hybrid if:**
- You want best of both worlds
- Complex retrieval requirements
- Production-grade system
- Can handle implementation complexity

**For WebMCP: SQL-First with optional embeddings is the sweet spot.** âœ…

---

## ğŸ‰ Conclusion

The trend is clear: **move away from pure RAG toward SQL-first hybrid systems**.

Your stack (TypeScript + Drizzle + PG-Lite + Zod) is **perfectly suited** for SQL-first memory:
- Type-safe schemas with Zod
- Powerful queries with Drizzle
- Local storage with PG-Lite
- WebMCP tools for external access

Start with structured entities + SQL retrieval. Add embeddings only if/when needed. Focus on transparency, portability, and cost-efficiency.

ğŸš€ **Let's build the future of agent memory!**
